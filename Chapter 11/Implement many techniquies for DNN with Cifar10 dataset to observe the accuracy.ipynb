{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\",save_best_only=True)\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_log\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2864), started 0:20:50 ago. (Use '!kill 2864' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-66f4193fa4d7722\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-66f4193fa4d7722\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16549731922312511031\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3142752667\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4586947970703211115\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 18s 397us/sample - loss: 4.1080 - accuracy: 0.1669 - val_loss: 2.2234 - val_accuracy: 0.1922\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 2.0740 - accuracy: 0.2455 - val_loss: 1.9972 - val_accuracy: 0.2780\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 14s 317us/sample - loss: 1.9492 - accuracy: 0.2894 - val_loss: 1.9535 - val_accuracy: 0.3014\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 14s 319us/sample - loss: 1.8656 - accuracy: 0.3206 - val_loss: 1.8267 - val_accuracy: 0.3382\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 15s 325us/sample - loss: 1.7994 - accuracy: 0.3474 - val_loss: 1.7737 - val_accuracy: 0.3558\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 1.7557 - accuracy: 0.3644 - val_loss: 1.7442 - val_accuracy: 0.3714\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 1.7102 - accuracy: 0.3805 - val_loss: 1.7654 - val_accuracy: 0.3632\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 14s 319us/sample - loss: 1.6736 - accuracy: 0.3957 - val_loss: 1.7275 - val_accuracy: 0.3812\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 14s 316us/sample - loss: 1.6417 - accuracy: 0.4076 - val_loss: 1.6683 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 14s 311us/sample - loss: 1.6150 - accuracy: 0.4190 - val_loss: 1.6568 - val_accuracy: 0.3934\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 1.5930 - accuracy: 0.4264 - val_loss: 1.6133 - val_accuracy: 0.4158\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.5735 - accuracy: 0.4338 - val_loss: 1.6429 - val_accuracy: 0.4098\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 14s 313us/sample - loss: 1.5529 - accuracy: 0.4428 - val_loss: 1.5923 - val_accuracy: 0.4262\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.5359 - accuracy: 0.4492 - val_loss: 1.5983 - val_accuracy: 0.4272\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 14s 314us/sample - loss: 1.5204 - accuracy: 0.4504 - val_loss: 1.5587 - val_accuracy: 0.4358\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.5030 - accuracy: 0.4594 - val_loss: 1.6176 - val_accuracy: 0.4228\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 14s 322us/sample - loss: 1.4906 - accuracy: 0.4648 - val_loss: 1.6252 - val_accuracy: 0.4186\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 1.4785 - accuracy: 0.4704 - val_loss: 1.5493 - val_accuracy: 0.4488\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.4644 - accuracy: 0.4769 - val_loss: 1.5684 - val_accuracy: 0.4340\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 1.4544 - accuracy: 0.4763 - val_loss: 1.5465 - val_accuracy: 0.4414\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 14s 312us/sample - loss: 1.4402 - accuracy: 0.4825 - val_loss: 1.5698 - val_accuracy: 0.4414\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 14s 314us/sample - loss: 1.4278 - accuracy: 0.4875 - val_loss: 1.5787 - val_accuracy: 0.4312\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.4181 - accuracy: 0.4909 - val_loss: 1.5720 - val_accuracy: 0.4382\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.4033 - accuracy: 0.4961 - val_loss: 1.5469 - val_accuracy: 0.4520\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 14s 315us/sample - loss: 1.3987 - accuracy: 0.4978 - val_loss: 1.5509 - val_accuracy: 0.4482\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 14s 311us/sample - loss: 1.3848 - accuracy: 0.5027 - val_loss: 1.5487 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 15s 334us/sample - loss: 1.3773 - accuracy: 0.5026 - val_loss: 1.5219 - val_accuracy: 0.4624\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 15s 326us/sample - loss: 1.3664 - accuracy: 0.5095 - val_loss: 1.5397 - val_accuracy: 0.4528\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 14s 317us/sample - loss: 1.3535 - accuracy: 0.5136 - val_loss: 1.5111 - val_accuracy: 0.4704\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 14s 313us/sample - loss: 1.3502 - accuracy: 0.5145 - val_loss: 1.5016 - val_accuracy: 0.4692\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 14s 318us/sample - loss: 1.3377 - accuracy: 0.5190 - val_loss: 1.5347 - val_accuracy: 0.4514\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 13s 300us/sample - loss: 1.3303 - accuracy: 0.5206 - val_loss: 1.5293 - val_accuracy: 0.4618\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 14s 317us/sample - loss: 1.3195 - accuracy: 0.5245 - val_loss: 1.5125 - val_accuracy: 0.4602\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.3112 - accuracy: 0.5269 - val_loss: 1.5090 - val_accuracy: 0.4724\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 1.3052 - accuracy: 0.5284 - val_loss: 1.5027 - val_accuracy: 0.4662\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.2931 - accuracy: 0.5350 - val_loss: 1.5086 - val_accuracy: 0.4646\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 14s 310us/sample - loss: 1.2872 - accuracy: 0.5369 - val_loss: 1.5135 - val_accuracy: 0.4616\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 14s 308us/sample - loss: 1.2776 - accuracy: 0.5381 - val_loss: 1.5128 - val_accuracy: 0.4716\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.2732 - accuracy: 0.5418 - val_loss: 1.5221 - val_accuracy: 0.4672\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.2629 - accuracy: 0.5454 - val_loss: 1.5358 - val_accuracy: 0.4698\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.2586 - accuracy: 0.5479 - val_loss: 1.5210 - val_accuracy: 0.4748\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 1.2512 - accuracy: 0.5500 - val_loss: 1.5256 - val_accuracy: 0.4706\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 13s 299us/sample - loss: 1.2406 - accuracy: 0.5531 - val_loss: 1.5185 - val_accuracy: 0.4714\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 14s 300us/sample - loss: 1.2315 - accuracy: 0.5561 - val_loss: 1.5503 - val_accuracy: 0.4710\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.2291 - accuracy: 0.5572 - val_loss: 1.4945 - val_accuracy: 0.4766\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.2209 - accuracy: 0.5612 - val_loss: 1.5005 - val_accuracy: 0.4836\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.2112 - accuracy: 0.5672 - val_loss: 1.5614 - val_accuracy: 0.4632\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 14s 300us/sample - loss: 1.2083 - accuracy: 0.5640 - val_loss: 1.5547 - val_accuracy: 0.4658\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.2003 - accuracy: 0.5686 - val_loss: 1.5358 - val_accuracy: 0.4750\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 14s 310us/sample - loss: 1.1950 - accuracy: 0.5671 - val_loss: 1.5474 - val_accuracy: 0.4714\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.1886 - accuracy: 0.5720 - val_loss: 1.5800 - val_accuracy: 0.4632\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 14s 314us/sample - loss: 1.1806 - accuracy: 0.5751 - val_loss: 1.5465 - val_accuracy: 0.4614\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 1.1745 - accuracy: 0.5778 - val_loss: 1.5889 - val_accuracy: 0.4630\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 14s 315us/sample - loss: 1.1666 - accuracy: 0.5788 - val_loss: 1.5705 - val_accuracy: 0.4696\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 15s 329us/sample - loss: 1.1619 - accuracy: 0.5824 - val_loss: 1.5841 - val_accuracy: 0.4576\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 14s 316us/sample - loss: 1.1515 - accuracy: 0.5851 - val_loss: 1.5715 - val_accuracy: 0.4730\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 14s 312us/sample - loss: 1.1512 - accuracy: 0.5844 - val_loss: 1.5792 - val_accuracy: 0.4602\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 14s 308us/sample - loss: 1.1393 - accuracy: 0.5887 - val_loss: 1.5564 - val_accuracy: 0.4638\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 14s 312us/sample - loss: 1.1378 - accuracy: 0.5905 - val_loss: 1.5643 - val_accuracy: 0.4684\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 13s 298us/sample - loss: 1.1281 - accuracy: 0.5943 - val_loss: 1.5730 - val_accuracy: 0.4650\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.1228 - accuracy: 0.5964 - val_loss: 1.5607 - val_accuracy: 0.4708\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 14s 310us/sample - loss: 1.1176 - accuracy: 0.5974 - val_loss: 1.5759 - val_accuracy: 0.4786\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 1.1097 - accuracy: 0.6000 - val_loss: 1.6111 - val_accuracy: 0.4618\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 14s 313us/sample - loss: 1.1128 - accuracy: 0.6005 - val_loss: 1.6127 - val_accuracy: 0.4582\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.0994 - accuracy: 0.6063 - val_loss: 1.6505 - val_accuracy: 0.4618\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "         callbacks=callbacks,use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 118us/sample - loss: 1.4945 - accuracy: 0.4766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4945455801010132, 0.4766]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 43s 957us/sample - loss: 1.8364 - accuracy: 0.3414 - val_loss: 1.6465 - val_accuracy: 0.4138\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 34s 755us/sample - loss: 1.6652 - accuracy: 0.4062 - val_loss: 1.6149 - val_accuracy: 0.4180\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 33s 744us/sample - loss: 1.5981 - accuracy: 0.4303 - val_loss: 1.5207 - val_accuracy: 0.4578\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 34s 749us/sample - loss: 1.5432 - accuracy: 0.4525 - val_loss: 1.4723 - val_accuracy: 0.4674\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 33s 738us/sample - loss: 1.5009 - accuracy: 0.4660 - val_loss: 1.4800 - val_accuracy: 0.4732\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 1.4629 - accuracy: 0.4787 - val_loss: 1.4371 - val_accuracy: 0.4932\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 34s 757us/sample - loss: 1.4332 - accuracy: 0.4945 - val_loss: 1.3867 - val_accuracy: 0.5032\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 34s 752us/sample - loss: 1.4055 - accuracy: 0.5020 - val_loss: 1.3844 - val_accuracy: 0.5056\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 1.3774 - accuracy: 0.5113 - val_loss: 1.3681 - val_accuracy: 0.5190\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 33s 742us/sample - loss: 1.3531 - accuracy: 0.5202 - val_loss: 1.3486 - val_accuracy: 0.5190\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 33s 743us/sample - loss: 1.3325 - accuracy: 0.5285 - val_loss: 1.3653 - val_accuracy: 0.5230\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 34s 747us/sample - loss: 1.3116 - accuracy: 0.5381 - val_loss: 1.3823 - val_accuracy: 0.5138\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 33s 743us/sample - loss: 1.2987 - accuracy: 0.5404 - val_loss: 1.3514 - val_accuracy: 0.5302\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 34s 744us/sample - loss: 1.2747 - accuracy: 0.5502 - val_loss: 1.3521 - val_accuracy: 0.5236\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 33s 739us/sample - loss: 1.2623 - accuracy: 0.5545 - val_loss: 1.3649 - val_accuracy: 0.5098\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 34s 746us/sample - loss: 1.2460 - accuracy: 0.5582 - val_loss: 1.3522 - val_accuracy: 0.5318\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 34s 746us/sample - loss: 1.2321 - accuracy: 0.5656 - val_loss: 1.3297 - val_accuracy: 0.5334- l\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 33s 740us/sample - loss: 1.2172 - accuracy: 0.5703 - val_loss: 1.3361 - val_accuracy: 0.5390\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 34s 747us/sample - loss: 1.1968 - accuracy: 0.5785 - val_loss: 1.3217 - val_accuracy: 0.5398\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 34s 748us/sample - loss: 1.1873 - accuracy: 0.5811 - val_loss: 1.3399 - val_accuracy: 0.5320\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 1.1778 - accuracy: 0.5835 - val_loss: 1.3383 - val_accuracy: 0.5374\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 34s 746us/sample - loss: 1.1670 - accuracy: 0.5902 - val_loss: 1.3409 - val_accuracy: 0.5318\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 35s 768us/sample - loss: 1.1511 - accuracy: 0.5939 - val_loss: 1.3126 - val_accuracy: 0.5414\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 33s 725us/sample - loss: 1.1348 - accuracy: 0.6002 - val_loss: 1.3480 - val_accuracy: 0.5330\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 33s 736us/sample - loss: 1.1231 - accuracy: 0.6023 - val_loss: 1.3384 - val_accuracy: 0.5450\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 33s 732us/sample - loss: 1.1128 - accuracy: 0.6075 - val_loss: 1.3366 - val_accuracy: 0.5384\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 34s 752us/sample - loss: 1.1006 - accuracy: 0.6102 - val_loss: 1.3657 - val_accuracy: 0.5416\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 1.0875 - accuracy: 0.6161 - val_loss: 1.3630 - val_accuracy: 0.5374\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 33s 742us/sample - loss: 1.0789 - accuracy: 0.6207 - val_loss: 1.3265 - val_accuracy: 0.5476\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 33s 743us/sample - loss: 1.0724 - accuracy: 0.6236 - val_loss: 1.3422 - val_accuracy: 0.5366\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 34s 750us/sample - loss: 1.0583 - accuracy: 0.6270 - val_loss: 1.3694 - val_accuracy: 0.5296\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 33s 739us/sample - loss: 1.0493 - accuracy: 0.6289 - val_loss: 1.3464 - val_accuracy: 0.5424\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 1.0391 - accuracy: 0.6329 - val_loss: 1.3395 - val_accuracy: 0.5460\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 33s 735us/sample - loss: 1.0269 - accuracy: 0.6388 - val_loss: 1.3600 - val_accuracy: 0.5402\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 33s 735us/sample - loss: 1.0217 - accuracy: 0.6371 - val_loss: 1.3907 - val_accuracy: 0.5360\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 33s 725us/sample - loss: 1.0085 - accuracy: 0.6428 - val_loss: 1.3366 - val_accuracy: 0.5450\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 34s 757us/sample - loss: 0.9983 - accuracy: 0.6467 - val_loss: 1.3341 - val_accuracy: 0.5494\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 35s 767us/sample - loss: 0.9893 - accuracy: 0.6497 - val_loss: 1.3789 - val_accuracy: 0.5474\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 33s 742us/sample - loss: 0.9873 - accuracy: 0.6495 - val_loss: 1.3617 - val_accuracy: 0.5458\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 33s 741us/sample - loss: 0.9725 - accuracy: 0.6572 - val_loss: 1.3934 - val_accuracy: 0.5356\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 34s 752us/sample - loss: 0.9636 - accuracy: 0.6579 - val_loss: 1.3866 - val_accuracy: 0.5306\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 34s 751us/sample - loss: 0.9585 - accuracy: 0.6609 - val_loss: 1.3830 - val_accuracy: 0.5448\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 36s 804us/sample - loss: 0.9447 - accuracy: 0.6658 - val_loss: 1.3751 - val_accuracy: 0.5426\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\",save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_log\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train,y_train, epochs=100,\n",
    "             validation_data=(X_valid,y_valid),\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 250us/sample - loss: 1.3126 - accuracy: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3125772806167602, 0.5414]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"lecun_normal\",\n",
    "                                activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\",save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\",\"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scale = (X_train - X_means) / X_stds\n",
    "X_valid_scale = (X_valid - X_means) / X_stds\n",
    "X_test_scale = (X_test - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 17s 375us/sample - loss: 1.9134 - accuracy: 0.3092 - val_loss: 1.8427 - val_accuracy: 0.3426\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 1.6943 - accuracy: 0.3994 - val_loss: 1.7828 - val_accuracy: 0.3838\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 1.6050 - accuracy: 0.4354 - val_loss: 1.6301 - val_accuracy: 0.4270\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 1.5352 - accuracy: 0.4638 - val_loss: 1.5933 - val_accuracy: 0.4572\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 1.4781 - accuracy: 0.4819 - val_loss: 1.5639 - val_accuracy: 0.4440\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.4337 - accuracy: 0.4986 - val_loss: 1.5439 - val_accuracy: 0.4680\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.3945 - accuracy: 0.5134 - val_loss: 1.4955 - val_accuracy: 0.4772\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.3532 - accuracy: 0.5276 - val_loss: 1.4946 - val_accuracy: 0.4920\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 1.3213 - accuracy: 0.5401 - val_loss: 1.4993 - val_accuracy: 0.4912\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.2957 - accuracy: 0.5507 - val_loss: 1.5118 - val_accuracy: 0.4928\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.2669 - accuracy: 0.5607 - val_loss: 1.5134 - val_accuracy: 0.4902\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 14s 304us/sample - loss: 1.2381 - accuracy: 0.5693 - val_loss: 1.4930 - val_accuracy: 0.5038\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.2188 - accuracy: 0.5795 - val_loss: 1.4847 - val_accuracy: 0.5036\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 14s 308us/sample - loss: 1.1938 - accuracy: 0.5891 - val_loss: 1.4565 - val_accuracy: 0.5020\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 1.1652 - accuracy: 0.5993 - val_loss: 1.5622 - val_accuracy: 0.4810\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.1524 - accuracy: 0.6040 - val_loss: 1.4565 - val_accuracy: 0.5048\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 1.1237 - accuracy: 0.6145 - val_loss: 1.5042 - val_accuracy: 0.5040\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.0969 - accuracy: 0.6223 - val_loss: 1.4785 - val_accuracy: 0.5136\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.0806 - accuracy: 0.6300 - val_loss: 1.4841 - val_accuracy: 0.5184\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 1.0551 - accuracy: 0.6397 - val_loss: 1.4814 - val_accuracy: 0.4974\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 1.0438 - accuracy: 0.6435 - val_loss: 1.5515 - val_accuracy: 0.5100\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 14s 300us/sample - loss: 1.0261 - accuracy: 0.6502 - val_loss: 1.5417 - val_accuracy: 0.5074\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 1.0121 - accuracy: 0.6560 - val_loss: 1.5364 - val_accuracy: 0.4994\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 14s 302us/sample - loss: 0.9959 - accuracy: 0.6630 - val_loss: 1.5747 - val_accuracy: 0.5124\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 0.9800 - accuracy: 0.6651 - val_loss: 1.5762 - val_accuracy: 0.5020\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 13s 299us/sample - loss: 1.0075 - accuracy: 0.6624 - val_loss: 1.5985 - val_accuracy: 0.5022\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 14s 303us/sample - loss: 0.9470 - accuracy: 0.6791 - val_loss: 1.6120 - val_accuracy: 0.4988\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 0.9181 - accuracy: 0.6904 - val_loss: 1.5714 - val_accuracy: 0.5026\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 14s 307us/sample - loss: 0.9154 - accuracy: 0.6922 - val_loss: 1.6532 - val_accuracy: 0.5056\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 0.8979 - accuracy: 0.6979 - val_loss: 1.5731 - val_accuracy: 0.5136\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 14s 301us/sample - loss: 0.8843 - accuracy: 0.7012 - val_loss: 1.7117 - val_accuracy: 0.5018\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 14s 305us/sample - loss: 0.8865 - accuracy: 0.7038 - val_loss: 1.6740 - val_accuracy: 0.5100\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 14s 309us/sample - loss: 0.8694 - accuracy: 0.7087 - val_loss: 1.7176 - val_accuracy: 0.5006\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 13s 298us/sample - loss: 0.8679 - accuracy: 0.7086 - val_loss: 1.6470 - val_accuracy: 0.5150\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 13s 298us/sample - loss: 0.8482 - accuracy: 0.7186 - val_loss: 1.6689 - val_accuracy: 0.5060\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 13s 297us/sample - loss: 0.8473 - accuracy: 0.7173 - val_loss: 1.7253 - val_accuracy: 0.4964\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train_scale,y_train, epochs=100,\n",
    "             validation_data=(X_valid_scale,y_valid),\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 130us/sample - loss: 1.4565 - accuracy: 0.5048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.456472645187378, 0.5048]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scale,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 19s 415us/sample - loss: 1.8772 - accuracy: 0.3334 - val_loss: 1.7490 - val_accuracy: 0.3884\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 15s 331us/sample - loss: 1.6488 - accuracy: 0.4151 - val_loss: 1.8019 - val_accuracy: 0.4086\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 15s 335us/sample - loss: 1.5614 - accuracy: 0.4495 - val_loss: 1.7122 - val_accuracy: 0.4436\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 15s 335us/sample - loss: 1.4949 - accuracy: 0.4736 - val_loss: 1.6085 - val_accuracy: 0.4380\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 15s 337us/sample - loss: 1.4384 - accuracy: 0.4962 - val_loss: 1.5393 - val_accuracy: 0.4776\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 15s 335us/sample - loss: 1.3956 - accuracy: 0.5133 - val_loss: 1.5038 - val_accuracy: 0.4980\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 15s 335us/sample - loss: 1.3521 - accuracy: 0.5277 - val_loss: 1.5419 - val_accuracy: 0.4826\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 15s 339us/sample - loss: 1.3153 - accuracy: 0.5431 - val_loss: 1.5373 - val_accuracy: 0.4892\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 15s 334us/sample - loss: 1.2763 - accuracy: 0.5551 - val_loss: 1.5651 - val_accuracy: 0.4906\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 15s 331us/sample - loss: 1.2410 - accuracy: 0.5698 - val_loss: 1.5646 - val_accuracy: 0.4938\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 15s 331us/sample - loss: 1.2151 - accuracy: 0.5822 - val_loss: 1.5815 - val_accuracy: 0.5008\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 15s 333us/sample - loss: 1.1848 - accuracy: 0.5909 - val_loss: 1.5978 - val_accuracy: 0.4858\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 15s 334us/sample - loss: 1.1560 - accuracy: 0.6001 - val_loss: 1.5667 - val_accuracy: 0.5034\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 15s 331us/sample - loss: 1.1260 - accuracy: 0.6169 - val_loss: 1.5771 - val_accuracy: 0.5022\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 15s 325us/sample - loss: 1.1021 - accuracy: 0.6239 - val_loss: 1.6292 - val_accuracy: 0.4930\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 15s 329us/sample - loss: 1.0794 - accuracy: 0.6301 - val_loss: 1.5735 - val_accuracy: 0.5098\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 15s 332us/sample - loss: 1.0539 - accuracy: 0.6372 - val_loss: 1.6408 - val_accuracy: 0.5018\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 15s 327us/sample - loss: 1.0269 - accuracy: 0.6472 - val_loss: 1.5883 - val_accuracy: 0.5114\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 15s 335us/sample - loss: 1.0128 - accuracy: 0.6555 - val_loss: 1.6602 - val_accuracy: 0.5096\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 15s 330us/sample - loss: 0.9858 - accuracy: 0.6666 - val_loss: 1.6100 - val_accuracy: 0.5142\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 15s 329us/sample - loss: 0.9661 - accuracy: 0.6693 - val_loss: 1.7674 - val_accuracy: 0.5012\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 15s 329us/sample - loss: 0.9482 - accuracy: 0.6795 - val_loss: 1.8125 - val_accuracy: 0.5052\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 15s 330us/sample - loss: 0.9268 - accuracy: 0.6867 - val_loss: 1.8521 - val_accuracy: 0.5010\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 15s 327us/sample - loss: 0.9131 - accuracy: 0.6903 - val_loss: 1.7368 - val_accuracy: 0.5154\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 15s 337us/sample - loss: 0.8884 - accuracy: 0.7009 - val_loss: 1.8334 - val_accuracy: 0.5104\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 15s 336us/sample - loss: 0.8801 - accuracy: 0.7020 - val_loss: 1.8198 - val_accuracy: 0.5064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ea04ecdc08>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 132us/sample - loss: 1.5038 - accuracy: 0.4980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5037678070068359, 0.498]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self,inputs):\n",
    "        return super().call(inputs,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_sample=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_sample)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "def mc_dropout_predict_classes(mc_model, X, n_sample=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_sample)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4984"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:,0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 5, 4, 6], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: nan - accuracy: 0.1388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.999999747378752e-06,\n",
       " 9.999868392944336,\n",
       " 2.0554909706115723,\n",
       " 3.4577737535749167)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "45000/45000 [==============================] - 4s 89us/sample - loss: 2.0599 - accuracy: 0.2796 - val_loss: 1.7734 - val_accuracy: 0.3662\n",
      "Epoch 2/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 1.7774 - accuracy: 0.3703 - val_loss: 1.7073 - val_accuracy: 0.4020\n",
      "Epoch 3/30\n",
      "45000/45000 [==============================] - 3s 58us/sample - loss: 1.6450 - accuracy: 0.4177 - val_loss: 1.6178 - val_accuracy: 0.4252\n",
      "Epoch 4/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.5586 - accuracy: 0.4474 - val_loss: 1.5579 - val_accuracy: 0.4502\n",
      "Epoch 5/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.4985 - accuracy: 0.4721 - val_loss: 1.5526 - val_accuracy: 0.4566\n",
      "Epoch 6/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.4479 - accuracy: 0.4878 - val_loss: 1.5596 - val_accuracy: 0.4590\n",
      "Epoch 7/30\n",
      "45000/45000 [==============================] - 3s 58us/sample - loss: 1.4102 - accuracy: 0.4985 - val_loss: 1.5778 - val_accuracy: 0.4588\n",
      "Epoch 8/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.3716 - accuracy: 0.5130 - val_loss: 1.5809 - val_accuracy: 0.4618\n",
      "Epoch 9/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 1.3415 - accuracy: 0.5224 - val_loss: 1.5576 - val_accuracy: 0.4584\n",
      "Epoch 10/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 1.3117 - accuracy: 0.5351 - val_loss: 1.5399 - val_accuracy: 0.4730\n",
      "Epoch 11/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 1.2855 - accuracy: 0.5423 - val_loss: 1.5513 - val_accuracy: 0.4882\n",
      "Epoch 12/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 1.2632 - accuracy: 0.5507 - val_loss: 1.6533 - val_accuracy: 0.4602\n",
      "Epoch 13/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 1.2435 - accuracy: 0.5593 - val_loss: 1.5817 - val_accuracy: 0.4712\n",
      "Epoch 14/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 1.2130 - accuracy: 0.5683 - val_loss: 1.5994 - val_accuracy: 0.4766\n",
      "Epoch 15/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 1.1670 - accuracy: 0.5859 - val_loss: 1.5595 - val_accuracy: 0.4880\n",
      "Epoch 16/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.1175 - accuracy: 0.6023 - val_loss: 1.6013 - val_accuracy: 0.4832\n",
      "Epoch 17/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 1.0672 - accuracy: 0.6200 - val_loss: 1.5768 - val_accuracy: 0.4874\n",
      "Epoch 18/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 1.0158 - accuracy: 0.6396 - val_loss: 1.5747 - val_accuracy: 0.5044\n",
      "Epoch 19/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 0.9708 - accuracy: 0.6532 - val_loss: 1.5629 - val_accuracy: 0.5084\n",
      "Epoch 20/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 0.9200 - accuracy: 0.6712 - val_loss: 1.6538 - val_accuracy: 0.5148\n",
      "Epoch 21/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 0.8718 - accuracy: 0.6877 - val_loss: 1.6953 - val_accuracy: 0.5042\n",
      "Epoch 22/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 0.8248 - accuracy: 0.7062 - val_loss: 1.7156 - val_accuracy: 0.5158\n",
      "Epoch 23/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 0.7704 - accuracy: 0.7256 - val_loss: 1.7861 - val_accuracy: 0.5166\n",
      "Epoch 24/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 0.7166 - accuracy: 0.7439 - val_loss: 1.8019 - val_accuracy: 0.5238\n",
      "Epoch 25/30\n",
      "45000/45000 [==============================] - 3s 56us/sample - loss: 0.6608 - accuracy: 0.7639 - val_loss: 1.9326 - val_accuracy: 0.5224\n",
      "Epoch 26/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 0.6078 - accuracy: 0.7851 - val_loss: 2.0241 - val_accuracy: 0.5246\n",
      "Epoch 27/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 0.5557 - accuracy: 0.8038 - val_loss: 2.0863 - val_accuracy: 0.5270\n",
      "Epoch 28/30\n",
      "45000/45000 [==============================] - 2s 55us/sample - loss: 0.5162 - accuracy: 0.8201 - val_loss: 2.1453 - val_accuracy: 0.5186\n",
      "Epoch 29/30\n",
      "45000/45000 [==============================] - 3s 58us/sample - loss: 0.4912 - accuracy: 0.8293 - val_loss: 2.1925 - val_accuracy: 0.5218\n",
      "Epoch 30/30\n",
      "45000/45000 [==============================] - 3s 57us/sample - loss: 0.4705 - accuracy: 0.8386 - val_loss: 2.2127 - val_accuracy: 0.5226\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 96us/sample - loss: 2.2127 - accuracy: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.212707152557373, 0.5226]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
